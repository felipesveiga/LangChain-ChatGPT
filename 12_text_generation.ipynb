{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e68615c-17fd-4873-993d-f56e04696ee5",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Self-Improving Text Generation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b5521-5313-4142-abe3-e9474f43cee6",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Random Component Parts</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Nós montamos nosso projeto sobre componentes fixos, sem experimentar outras alternativas. Por exemplo, utilizamos somente o GPT-3.5 Turbo para a geração de nossas respostas, e recorremos ao Pinecone como vectorstore.\n",
    "        </li>\n",
    "        <li>\n",
    "            No entanto, nós não sabemos se essa combinação de componentes é a que dará melhor resultado à nossa aplicação. Por isso, vamos possibilitar que o site inicialize chains com componentes diferentes para cada chat.\n",
    "        </li>\n",
    "        <li>\n",
    "            Nós coletaremos feedbacks de nossos usuários (likes, dislikes), a fim de se concluir qual combinação de peças mais satisfaz nossos clientes.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ec764-7707-47df-8c9e-3e76b2d5b8f5",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Random Component Parts</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Nós montamos nosso projeto sobre componentes fixos, sem experimentar outras alternativas. Por exemplo, utilizamos somente o GPT-3.5 Turbo para a geração de nossas respostas, e recorremos ao Pinecone como vectorstore.\n",
    "        </li>\n",
    "        <li>\n",
    "            No entanto, nós não sabemos se essa combinação de componentes é a que dará melhor resultado à nossa aplicação. Por isso, vamos possibilitar que o site inicialize chains com componentes diferentes para cada chat.\n",
    "        </li>\n",
    "        <li>\n",
    "            Nós coletaremos feedbacks de nossos usuários (likes, dislikes), a fim de se concluir qual combinação de peças mais satisfaz nossos clientes.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af6eb8-c346-463d-a348-839c6830c201",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Component Part Flow</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Nós deveremos criar um mecanismo que definirá as peças utilizadas por uma certa conversa. Uma vez definidos os componentes, nós criaremos um mecanismo que os carregará, caso o chat seja continuado em um momento posterior.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5f383-2573-40bf-aa45-6f85fefbc65c",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Partial KWArg Application</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Montagem do nosso mecanismo de escolha do LLM. Nós deixaremos nossa função `build_llm` pré-inicializada com o nome de nosso modelo escolhido (`functools.partial`). Assim, nós poderemos executá-la plenamente, passando somente um 'ChatArgs`.\n",
    "            <center style='margin-top:20px'>\n",
    "                <img src='img/12_partial_llm.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239230e4-3fb4-4adb-9bb9-d93f13a69594",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Building Component Maps</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Agora, criaremos as opções de configuração para o retriever do Pinecone.\n",
    "        </li>\n",
    "        <li>\n",
    "            Nós passaremos diversas opções de top-k documentos a serem resgatados da Vector Store.\n",
    "        </li>\n",
    "        <li>\n",
    "            Inicializamos nosso dicionário de opções de memória, também.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806db8d1-6601-4aed-9fbf-79718584a479",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Collecting User Feedback</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Cuidaremos agora do mecanismo de coleta de feedbacks dos usuáriois sobre as respostas da plataforma.\n",
    "        </li>\n",
    "        <li>\n",
    "            Com o passar do tempo, o site tenderá a inicializar chains com componentes de maior reputação entre nossos clientes.\n",
    "        </li>\n",
    "        <li>\n",
    "            Thumbs up contarão como +1, enquanto down 0. O score final para um determinado recurso será a média de todas as pontuações.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ff356-bdb5-4c4b-9fee-034eae842333",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Redis Connection Setup</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Nós armazenaremos os scores de avaliação dentro do Redis. Como ele não possui uma função para cálculo de médias, vamos ter que medi-las manualmente.\n",
    "        </li>\n",
    "        <li>\n",
    "            Nós criaremos uma tabela com a soma dos scores, e outra com a contagem de avaliações, para cada recurso. Finalmente, mediremos o quociente.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14144a4a-a58b-4b64-ac70-7280944eac9b",
   "metadata": {},
   "source": [
    "<p style='color:red'> Vi Aula 123; Aula 124</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
