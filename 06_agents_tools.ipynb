{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cca2c62-973c-477e-befd-fcb463832903",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Empower ChatGPT with Tools and Agents</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4dade-f46a-4ecc-a69a-0aac23f4b283",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> App Overview</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Nesta seção, vamos criar uma aplicação que recorre a um LLM para consultar bancos de dados relacionais.\n",
    "        </li>\n",
    "        <li>\n",
    "            Dada uma pergunta da área de negócio, ele deverá escrever uma query que será executada no DB, e a responderá com base no output retornado.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655681d-d1ab-4a55-b345-37391576fac1",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Understanding Tools</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Tools são nada mais do que funções que descrevemos ao LLM para resolver determinada tarefa. Diante de um cenário, o modelo pode concluir de que  não é capaz de responder a pergunta, por si só, e recorrer a uma das tools definidas.\n",
    "        </li>\n",
    "        <li>\n",
    "            É claro que um modelo não é capaz de abrir o seu terminal e executar a função. O que nós o faremos responder será um JSON que informa a tool selecionada, juntamente com os argumentos a serem utilizados. Nós, posteriormente, vamos obter os valores do dicionário a fim de acionar a função (já escrita em código) em nosso computador.\n",
    "        </li>\n",
    "        <li>\n",
    "            Por fim, nós pegaremos o resultado da execução, e o daremos ao modelo para que ele possa responder a questão.\n",
    "        </li>\n",
    "    </ul>\n",
    "    <figure>\n",
    "        <center style='margin-top:20px'> \n",
    "            <img src='img/06_tool_definition.png'>\n",
    "            <figcaption> Exemplo da definição de uma função para escrita de queries.</figcaption>\n",
    "        </center>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c297904-2445-4947-ba86-e89cd7943ac2",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Understanding ChatGPT Functions</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Uma maneira um pouco mais concisa de definirmos funções ao ChatGPT seria com JSON's. Eles devem ter uma formatação especial que aprenderemos a seguir. Nós criamos uma lista dentro da qual vamos inserir as \"declarações\".\n",
    "            <center style='margin-top:20px'> \n",
    "                <img src='img/06_function_json.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "        <li style='margin-top:20px'>\n",
    "            Caso decida por utilizar nossa função, o ChatGPT retornará a sua resposta com uma chave \"function_call\", com o método escolhido e argumentos.\n",
    "            <center style='margin-top:20px'> \n",
    "                <img src='img/06_function_call.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72027b-5fcf-4b9b-baaf-c4069269ddfe",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Defining a Tool</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O LangChain possui uma classe que cuidará da formatação dos metadados de nossa função. Nós devemos passá-la junto com um determinado nome e descrição de suas funcionalidades.\n",
    "            <center style='margin-top:20px'> \n",
    "                <img src='img/06_tool.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857f84e-9e49-4e6a-8626-727b54ca880d",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Understanding Agents and AgentExecutors</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Aplicações que recorrem a Tools dependem de classes de Agents e AgentExecutor's.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4510ab-451b-426d-8117-0c654f8c6a22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Agents</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            As classes de Agent nada mais são do que chains. Elas vão receber uma lista de funções Python e criar JSON's com suas definições para serem enviadas à API do LLM.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e60337d-090b-46b0-9b68-8845f22d6bb5",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Agent Executor</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Agent Executors nada mais são do que loops de requisição ao LLM. Eles fazem chamadas ao modelo, enquanto sua resposta não for uma chamada de função.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658baa5-773a-4660-976a-701fd7bae896",
   "metadata": {},
   "source": [
    "<figure><center style='margin-top:20px'> \n",
    "    <img src='img/06_agents.png'>\n",
    "    <figcaption>Uso da classe de Agent e AgentExecutor para OpenAI</figcaption>\n",
    "    </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557e9ab-bedf-46da-abdc-fea1cc540022",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> initialize_agent</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O LangChain ainda conta com uma função que atua como um wrapper da invocação de um Agent e um AgentExecutor. A initialize_agent encapsula o uso das classes de uma só vez.\n",
    "            <center style='margin-top:20px'> \n",
    "                <img src='img/06_initialize_agent.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9412a-6f08-4f37-b699-506f1dca2dd2",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> agent_scratchpad (MessagesPlaceholder)</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Quando montamos nosso Prompt Template, devemos inserir um MessagesPlaceholder na lista de mensagens com uma `variable_name=\"agent_scratchpad\"`\n",
    "        </li>\n",
    "        <li>\n",
    "            Quando formos fazer nossa segunda requisição ao modelo (com o resultado da query), esse placeholder trará consigo o código da consulta e seu resultado para a contextualização do modelo.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e199991-4584-46f6-bb37-02bc34343de4",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Recovering from Errors in Tools</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Acrescentando uma pequena lógica que alertará o Chat-GPT em casos de falhas na execução de sua query. \n",
    "            <center style='margin-top:20px'> \n",
    "                <img src='img/06_oper_error.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63377b38-fa3a-4f97-a616-4d2784067631",
   "metadata": {},
   "source": [
    "<p style='color:red'> Vi Aula 55; Aula 56</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
