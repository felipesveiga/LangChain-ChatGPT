{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979062c4-dca2-49d4-abc8-c899272a5e08",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Let's Start - Dive In Here!</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803565e-716d-4a52-840c-63429eeda120",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> How to Get Help</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O curso disponibiliza os code snippets de cada seção. Além disso, existe uma comunidade no Discord onde podemos sanar dúvidas.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e9424d-c131-4089-bca9-df8b4aa1cd82",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> What is LangChain?</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Para entendermos melhor como o LangChain funciona, nós utilizaremos primeiramente a API da pdf.AI. Aprenderemos o seu modo de atuação para depois discutirmos o pacote.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93799041-7577-4fda-9e2e-5ed40a94fcfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> How a Typical AI-Enabled App Works</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Vamos entender como o pdf.AI funciona.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0996b-4451-48ba-9289-87c81b388121",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Ciclo de Funcionamento do pdf.AI</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Quando o usuário carrega o pdf no site, o modelo quebra o texto em pedaços e atribui um embedding (vetor) a cada um deles.\n",
    "        </li>\n",
    "        <li> \n",
    "            Assim, quando o usuário fizer uma pergunta, o modelo procurará o fragmento mais relevante à questão para o retornar como resposta.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f15ea3-2375-42e4-80f8-0b0e3272c7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .ipynb_checkpoints/01_start-checkpoint.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   01_start.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "! git add .\n",
    "! git commit -m 'Aula 3 (05:25) Explicar como exatamente a busca pelo fragmento mais relevante é feita'\n",
    "! git push origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1420a5-12d2-4eda-9d1f-632723b0edc8",
   "metadata": {},
   "source": [
    "<p style='color:red'> Aula 3 (05:25) Explicar como exatamente a busca pelo fragmento mais relevante é feita</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
