{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea07b9b-2159-4337-a0f2-d526986a4ce6",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'>  Deep Dive into Interactions with Memory Management</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce62a0-6bd6-48bd-8860-61b1bdc585bf",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> App Overview</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>  \n",
    "            Vamos construir nesta seção um chatbot. Ele não apenas será capaz de responder os prompts do usuário, como também ser consciente do histórico da conversa.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5341ed-779d-4f87-8ff1-bde30ca7bbda",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Chat vs Completion Style Models</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>  \n",
    "            Os LLM's são divididos em diferentes modalidades. Existem tanto os modelos de chat (GPT, Bard), quanto os especializados em completar textos passados pelo usuário (text-davinci-003). Estes últimos são conhecidos como LLM's tradicionais; tanto é que a documentação do LangChain normalmente se refere a esse tipo de modelos, quando menciona o termo \"LLM\".\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb367f1-7a0a-491a-b5c8-c6f208c6d576",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Estruturação dos ChatBots</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Uma conversa com um LLM envolve 3 tipos de mensagens.\n",
    "            <ul> \n",
    "                <li> \n",
    "                    <i> System Message:</i> Mensagem pré-definida pelo desenvolvedor. Responsável por contextualizar o modelo sobre a situação de seu consumo.\n",
    "                </li>\n",
    "                <li> \n",
    "                    <i> User Message:</i> Input dado pelo cliente do chatbot.\n",
    "                </li>\n",
    "                <li> \n",
    "                    <i> Assistant Message:</i> Mensagem criada pelo LLM, normalmente em resposta à User Message.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bb165-7369-4288-94f5-7d13d594b565",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Manutenção de Diálogos</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Um LLM, por si só, é alheio a todo o histórico de sua conversa com o usuário. A sua conscientização sobre o contexto do diálogo é feita enviando a sequência anterior das mensagens, junto com o novo input do usuário.\n",
    "        </li>\n",
    "        <li>\n",
    "            Poderíamos dizer que ocorre o envio de um empilhado de mensagens, sendo a primeira delas a System Message, seguida das mensagens de usuário e assistente.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ea914-3e8b-4fec-acf9-49ef95ac4c21",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Representing Messages with ChatPromptTemplates</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>  \n",
    "            A criação de chatbots envolve o uso do ChatPromptTemplate. Ele encapsulará a mensagem de sistema e usuário com a SystemMessagePromptTemplate e HumanMessagePromptTemplate, respectivamente.\n",
    "        </li>\n",
    "        <li>\n",
    "            Ambos os templates mostrados poderão receber inputs do usuário, assim como o PromptTemplate que estudamos no último. \n",
    "            <center style='margin-top:20px'> \n",
    "                <img src='img/03_chat_template.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b4003-4107-448f-a2f7-d09858b2d4a1",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Understanding Memory</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>  \n",
    "            Aqui, aprenderemos o modus-operandi da memória de agentes conversacionais do LangChain.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0167ee0-e020-4d01-b4ba-41cd72c06da1",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> ConversationBufferMemory</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            ConversationBufferMemory será a classe usada como memória de nossos ChatBots.\n",
    "        </li>\n",
    "        <li>\n",
    "            Suas principais funcionalidades são:\n",
    "            <ul> \n",
    "                <li>\n",
    "                    Acrescentar novas variáveis ao dicionário de input.\n",
    "                </li>\n",
    "                <li> \n",
    "                    Adicionar mensagens ao histórico da conversa.\n",
    "                </li>\n",
    "            </ul>\n",
    "            <center style='margin-top:20px'> \n",
    "                <img src='img/03_conversation_buffer_memory.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "        <li>\n",
    "            O LangChain ainda oferece outras classes de memória, mas voltadas a modelos de completion.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ec5c7-bfe8-45ac-9d5b-bf9e41a0b75e",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Using ChatBufferMemory to Store Conversations</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>  \n",
    "            Agora, finalmente vamos pôr as mãos à obra e aprimorar nosso chatbot.\n",
    "        </li>\n",
    "        <li>\n",
    "            Ao instanciar a ConversationBufferMemory, o argumento `memory_key` sinalizará o nome da chave do dicionário de input que vai armazenar o histórico da conversa. Já `return_messages`, quando True, garantirá que as mensagens fiquem encapsuladas em `AIMessagePromptTemplate`, `HumanMessagePromptTemplate`, ao invés de meramente em strings.\n",
    "        </li>\n",
    "        <li>\n",
    "            Para assegurar que o histórico das mensagens vai ser recebido pelo LLM, passe a classe `MessagesPlaceholder` em primeiro lugar na lista de mensagens de `ChatPromptTemplate`. \n",
    "            <center style='margin-top:20px'> \n",
    "                <figure> \n",
    "                    <img src='img/03_message_placeholder.png'>\n",
    "                    <figcaption> Informe a chave com o histórico de mensagens em `input_variables` (ChatPromptTemplate) e `variable_name` (MessagesPlaceholder).</figcaption>\n",
    "                </figure>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ed079-eac2-4aee-8208-b9059ff525ff",
   "metadata": {},
   "source": [
    "<p style='color:red'> Aula 24</p>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
