{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cb4abc-c77e-44a3-bbd3-418701708200",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Custom Message Histories</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Esta seção será dedicada à montagem da interface de chat do nosso site. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70deb419-0f06-45d9-9b3f-8672dbb66c57",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Understanding the Apps Requirements</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            A montagem da interface envolverá certos desafios, como a persistência das mensagens trocadas nos diversos chats tidos. Além disso, vamos ter que garantir que a nossa classe de RAG resgate apenas os chunks referentes ao pdf escolhido. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56547f-4ec2-4d13-bb46-8f95a78cb79f",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Persistent Message Storage</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            O desafio da filtragem dos embeddings pode ser resolvido passando um dicionário como parâmetro de nosso objeto retriever. No nosso caso, deveremos passar o id do pdf como nosso argumento. \n",
    "            <center style='margin-top:20px'>\n",
    "                <img src='img/09_rag_filter.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27808f-588f-4128-a1fe-ab2515cdf7d2",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Chat History Persistence</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Dado o alto volume de conversas esperado em nossa plataforma, não seria apropriado armazená-las todas em memória (ChatMemoryBuffer). \n",
    "        </li>\n",
    "        <li>\n",
    "            Ao invés disso, guardaremos todos os históricos numa DB SQLite. Quando um chat for continuado, faremos uma query que alocará somente o histórico do chat específico à nossa memória!\n",
    "        </li>\n",
    "        <li>\n",
    "            Essa tarefa demandará que nós criemos um objeto de memória customizado.\n",
    "            <center style='margin-top:20px'>\n",
    "                <img src='img/09_memory_persistence.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0cfee0-651b-4cdc-8189-13cefe1552d2",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Introducing the Conversational Retrieval Chain</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Apesar de o LangChain ter a classe `RetrievalQA`, essa não tem memória embutida. E mesmo se tentássemos acrescentar isso, a vetorização poderia estar sujeita a algumas imperfeições.\n",
    "        </li>\n",
    "        <li>\n",
    "            Foi considerando isso que o LangChain desenvolveu a ConversationalRetrievalChain. Nela, pedimos ao LLM para pôr um resumo da conversa até então, antes do texto da nova pergunta do usuário.\n",
    "        </li>\n",
    "        <li>\n",
    "            Tendo esse novo texto em mãos, o vetorizamos e fazemos um RAG na Vector DB para assim fazermos a requisição oficial ao LLM. Por fim, a resposta deste e a pergunta do usuário - e não o resumo do modelo!- são alocados à memória.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30dacb-d095-4558-aaac-5f4603e9b7eb",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Building the Retriever</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Construiremos aqui o retriever dos chunks da nossa aplicação. Quando um chat for iniciado, nossa função receberá uma classe do Pydantic com os metadados necessários para fazermos a query no Pinecone.\n",
    "            <center style='margin-top:20px'>\n",
    "                <img src='img/09_build_retriever.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767cf23-e6c3-4770-8ec6-53c0e0b210b7",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Custom History Objects</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Nos preocuparemos na próxima aula com a criação de uma classe de memória que armazenará o histórico das conversas em uma base de dados. \n",
    "        </li>\n",
    "        <li>\n",
    "            Ela será informada no argumento `chat_memory` da nossa `ConversationBufferMemory`.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385469d-2384-4176-ada4-7a1f9e5354ec",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <center style='margin-top:20px'>\n",
    "                <img src='img/09_memory_persistency.png'>\n",
    "        <figcaption> Lembre-se que nós já criamos um mecanismo de persistência de mensagens no projeto do tchat</figcaption>\n",
    "            </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af0b77-caf8-4184-a83c-4ffb62a3e53a",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Building a Custom SQL History</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Programamos nossa classe de persistência de memórias.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30939d-c645-4c7c-83f2-c1576c8a1b7d",
   "metadata": {},
   "source": [
    "<p style='color:red'> Vi Aulas 95; Ver Aula 96</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
